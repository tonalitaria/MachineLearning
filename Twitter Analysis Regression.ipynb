{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk as nlp\n",
    "from nltk import word_tokenize\n",
    "from nltk import TweetTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer(reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ted/Desktop/Project 3/amazon_yelp_twitter2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nearly perfect wheat-free bread mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>be aware: speakers not as advertised on amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>results comedic at best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>going to enjoy the sunshine while its here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>i feel better now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            text\n",
       "0          1             nearly perfect wheat-free bread mix\n",
       "1          0  be aware: speakers not as advertised on amazon\n",
       "2          0                         results comedic at best\n",
       "3          1      going to enjoy the sunshine while its here\n",
       "4          1                              i feel better now."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.iloc[:,:2].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[pd.notnull(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df2, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClfSwitcher(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator = SGDClassifier(),):\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorize', TfidfVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('clf', ClfSwitcher()),])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'clf__estimator': [MultinomialNB()],\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [LogisticRegression()],\n",
    "    },\n",
    "    {\n",
    "        'clf__estimator': [SGDClassifier()],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   6 | elapsed: 10.3min remaining: 20.6min\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   6 | elapsed: 17.9min finished\n",
      "/home/ted/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vectorize',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_...\n",
       "                                                           early_stopping=False,\n",
       "                                                           epsilon=0.1,\n",
       "                                                           eta0=0.0,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           l1_ratio=0.15,\n",
       "                                                           learning_rate='optimal',\n",
       "                                                           loss='hinge',\n",
       "                                                           max_iter=1000,\n",
       "                                                           n_iter_no_change=5,\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           power_t=0.5,\n",
       "                                                           random_state=None,\n",
       "                                                           shuffle=True,\n",
       "                                                           tol=0.001,\n",
       "                                                           validation_fraction=0.1,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv = GridSearchCV(pipeline, parameters, cv=2, n_jobs=4, return_train_score=False, verbose=3)\n",
    "gscv.fit(df_train.text, df_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([340.08255041, 471.05087054, 248.61485744]),\n",
       " 'mean_score_time': array([264.3739419 , 271.09122169, 205.87077367]),\n",
       " 'mean_test_score': array([0.77391349, 0.80119597, 0.77140628]),\n",
       " 'param_clf__estimator': masked_array(data=[MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "                    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       "                    SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "               power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=False)],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)},\n",
       "  {'clf__estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                      warm_start=False)},\n",
       "  {'clf__estimator': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                 early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                 l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "                 max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "                 power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "                 validation_fraction=0.1, verbose=0, warm_start=False)}],\n",
       " 'rank_test_score': array([2, 1, 3], dtype=int32),\n",
       " 'split0_test_score': array([0.77407078, 0.80109599, 0.77163745]),\n",
       " 'split1_test_score': array([0.77375619, 0.80129595, 0.77117511]),\n",
       " 'std_fit_time': array([2.13821566, 0.7224952 , 1.10864067]),\n",
       " 'std_score_time': array([2.56801295, 0.53618014, 1.80617249]),\n",
       " 'std_test_score': array([1.57297289e-04, 9.99824871e-05, 2.31169700e-04])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.cv_results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
